{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "import itertools\n",
    "import functools\n",
    "import time\n",
    "import h5py\n",
    "def norm_complex(arr: np.ndarray):\n",
    "    if len(arr.shape) > 1:\n",
    "        ret_out = np.zeros_like(arr)\n",
    "        for i in range(arr.shape[0]):\n",
    "            ret_out[i,:] = arr[i]/np.sqrt((np.abs(arr[i])**2).sum())  \n",
    "        return ret_out\n",
    "    else:\n",
    "        return arr/np.sqrt((np.abs(arr)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = np.array([[0, 1], [1, 0]])\n",
    "sy = np.array([[0, 1j], [-1j, 0]])\n",
    "sz = np.array([[1, 0], [0, -1]])\n",
    "basis = np.stack([np.eye(2), sx, sy, sz])\n",
    "\n",
    "n = 4 # Nb of qubits\n",
    "J = 4**n # Matches the number of bases\n",
    "I = 6**n # Matches  R*A = 2^n * 3^n = 6^n\n",
    "d = R = 2**n # matrix dimension and number of possibilities for R^a_s ({-1, 1}^n)\n",
    "A = 3**n # Number of possible measurements\n",
    "npa = np.array\n",
    "b = npa(list(itertools.product(range(4), repeat=n))) # {I, x, y, z}^n\n",
    "a = npa(list(itertools.product(range(1, 4), repeat=n))) # {x,y,z}^n\n",
    "# r = npa(list(itertools.product([1, 0], repeat=n))) # {0, 1}^n -> acts like a mask for which bases to select\n",
    "r = npa(list(itertools.product([-1, 1], repeat=n)))\n",
    "def projectors(idx_list, r_):\n",
    "    \"\"\"\n",
    "    Returns the P^{a_i}_{s_i} list of projection matrices\n",
    "    Note1: the evs returned by numpy and the ones obtained don't match, \n",
    "    but as they are not unique, it is still correct.\n",
    "    Note2: because we are working in R^2, we can use the [-1, 1] indexing\n",
    "    (which works differently in R - it removes the neg col - but still the same here)\n",
    "    \"\"\"\n",
    "    r_idx = [1 if i==-1 else 0 for i in r_]\n",
    "    evs = [eig(basis[i])[1] for i in idx_list]\n",
    "    selected_evs = np.array([ev[:, r_idx[i]] for i, ev in enumerate(evs)])\n",
    "    ret = npa([np.outer(np.conj(ev), ev) for ev in selected_evs])\n",
    "    # print(ret)\n",
    "    return ret\n",
    "\n",
    "# Corresponds to P^a_s in paper (each row here is a matrix), size: 2^n x 3^n flattened\n",
    "# The projectors matrices \n",
    "Pra = []\n",
    "for j in range(A):\n",
    "    for i in range(R):\n",
    "        # print(a[j], r[i])\n",
    "        # print(projectors(a[j], r[i]))\n",
    "        # print()\n",
    "        Pra.append(npa(functools.reduce(np.kron, projectors(a[j], r[i]))).flatten(\"F\"))\n",
    "Pra = npa(Pra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14654/1398590864.py:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  file.create_dataset('data', data=Pra.astype(float).T)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('Pra_py.h5', 'w') as file:\n",
    "    file.create_dataset('data', data=Pra.astype(float).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All possible combinations of a (kron product of all permutations)\n",
    "# Pauli basis for n qubit \n",
    "sig_b = npa([functools.reduce(np.kron, (basis[b[i,:], :, :])) for i in range(J)])\n",
    "\n",
    "\n",
    "# Only used for the calculation of rho_hat, \n",
    "### Maybe matches to p_a,s = P(R^a = s) in paper, size: 6^n x 4^n\n",
    "# For every comb of the bases (j in 0:J), then for every activation of the bases (r[s in S, ])\n",
    "# Matrix P_{(r,a),b} \n",
    "P_rab = np.zeros((I, J))\n",
    "for j in range(J):\n",
    "    tmp = np.zeros((R, A))\n",
    "    for s in range(R): # r_neg[s] = [-1, 1, -1, 1], b[j]=[1, 2, 0, 2], a[l] = [2, 4, 1, 1] \n",
    "        for l in range(A): #  r_neg[s, b[j] != 0] = [-1, 1, 1]\n",
    "            val = np.prod(r[s, b[j] != 0])\\\n",
    "                * np.prod(a[l, b[j] != 0] == b[j, b[j]!=0]) # a[l, b[j] != 0] == b[j, b[j] != 0] <=> [2, 4, 1] != [1, 2, 2] \n",
    "            tmp[s,l] = val\n",
    "    P_rab[:, j] = tmp.flatten(order=\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('P_rab_py.h5', 'w') as file:\n",
    "#     file.create_dataset('data', data=P_rab.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('sig_b_py.h5', 'w') as file:\n",
    "#     file.create_dataset('data', data=sig_b.astype(float).reshape(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = norm_complex(np.random.multivariate_normal(np.zeros(d*2),np.eye(d*2)/100, size=(d)).view(np.complex128))\n",
    "dens_ma = np.conj(u.T) @ u /d\n",
    "np.linalg.matrix_rank(dens_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1[0:int(d/2)] = 1\n",
    "v1 = norm_complex(v1)\n",
    "v2 = np.zeros(d)\n",
    "v2[int(d/2):d] = i\n",
    "v2 = norm_complex(v2)\n",
    "dens_ma = 1/2 * np.outer(v1, np.conj(v1)) + 1/2 * np.outer(v2, np.conj(v2))\n",
    "w = 0.98\n",
    "dens_ma = w * dens_ma + (1 - w) * np.eye(d)/d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(dens_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14654/1648047235.py:16: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  Prob_ar[i,j] = np.diag(dens_ma @ npa(functools.reduce(np.kron, projectors(a[i], r[j])))).sum()\n"
     ]
    }
   ],
   "source": [
    "# Pure state - rank1\n",
    "dens_ma = np.zeros((d, d))\n",
    "dens_ma[0, 0] = 1\n",
    "\n",
    "# Rank2\n",
    "v1 = np.zeros(d)\n",
    "v1[0:int(d/2)] = 1\n",
    "v1 = norm_complex(v1)\n",
    "v2 = np.zeros(d)\n",
    "v2[int(d/2):d] = 1j\n",
    "v2 = norm_complex(v2)\n",
    "dens_ma = 1/2 * np.outer(v1, np.conj(v1)) + 1/2 * np.outer(v2, np.conj(v2))\n",
    "\n",
    "# Approx rank2\n",
    "v1[0:int(d/2)] = 1\n",
    "v1 = norm_complex(v1)\n",
    "v2 = np.zeros(d)\n",
    "v2[int(d/2):d] = 1j\n",
    "v2 = norm_complex(v2)\n",
    "dens_ma = 1/2 * np.outer(v1, np.conj(v1)) + 1/2 * np.outer(v2, np.conj(v2))\n",
    "w = 0.98\n",
    "dens_ma = w * dens_ma + (1 - w) * np.eye(d)/d\n",
    "\n",
    "# Maximal mixed state (rank=16) - ground truth\n",
    "u = norm_complex(np.random.multivariate_normal(np.zeros(d*2),np.eye(d*2)/100, size=(d)).view(np.complex128))\n",
    "dens_ma = np.conj(u.T) @ u /d\n",
    "\n",
    "# Corresponds to Tr(rho \\dot P^a_s), which in turn corresponds to p_a,s\n",
    "# These probabilities are the true ones, so we do not have access to them\n",
    "# We use them below to measure the system\n",
    "Prob_ar = np.zeros((A, R))\n",
    "if n==1:\n",
    "    for i in range(A):\n",
    "        for j in range(R):\n",
    "            Prob_ar[i,j] = dens_ma.flatten(order=\"F\") @ projectors(a[i], r[j])\n",
    "else:\n",
    "    for i in range(A):\n",
    "        for j in range(R):\n",
    "            Prob_ar[i,j] = np.diag(dens_ma @ npa(functools.reduce(np.kron, projectors(a[i], r[j])))).sum()\n",
    "Prob_ar = np.real(Prob_ar)\n",
    "\n",
    "\n",
    "# For each observable, we sample according to the true probabilities calculated above\n",
    "# n_size samples, and then give the probability\n",
    "# For example: \n",
    "# if n=4 (qubits) and a_i = {x, x, y, z}, then an outcome could be s_j {-1, 1, -1, 1}\n",
    "# For this pair of a,s, we calculate the number of times we sampled this situation (the H == s part) \n",
    "#\n",
    "\n",
    "# Nb of times we repeat the measurements\n",
    "n_size = 2000\n",
    "p_ra = np.zeros((R, A)) # = \\hat{p}_a,s\n",
    "for i, x in enumerate(Prob_ar):\n",
    "    H = np.random.choice(R, n_size, replace=True, p=x) #n_size elements\n",
    "    out = []\n",
    "    for s in range(R):\n",
    "        out.append((H==s).sum()/n_size) # Calculate the empirical prob of this combination\n",
    "    p_ra[:, i] = out\n",
    "# Transform matrix to vector form\n",
    "p_ra1 = p_ra.flatten(order=\"F\")\n",
    "\n",
    "temp1 = p_ra1 @ P_rab\n",
    "temp1 = temp1/d\n",
    "\n",
    "# Calculate coefs rho_b\n",
    "rho_b = [0] * J\n",
    "for i in range(J):\n",
    "    rho_b[i] = temp1[i]/(3**((b[i] == 0).sum()))\n",
    "\n",
    "# Calculate density using inversion technique\n",
    "rho_hat = np.zeros((d, d), dtype=np.complex128)\n",
    "for s in range(J):\n",
    "    rho_hat += rho_b[s] * sig_b[s]\n",
    "# rho_hat = rho_hat.astype(float)\n",
    "u_hat = eig(rho_hat)[1]\n",
    "\n",
    "# renormalize lambda_hat\n",
    "lamb_til = eig(rho_hat)[0]\n",
    "lamb_til[lamb_til < 0] = 0\n",
    "lamb_hat = lamb_til/lamb_til.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot: 0.12956043099984527; p1: 0.0; p2: 0.0; p3: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a = time.perf_counter()\n",
    "part1 = 0\n",
    "part2 = 0\n",
    "part3 = 0\n",
    "for _ in range(10):\n",
    "    for i in range(int(2*d)):\n",
    "        p1s = time.perf_counter()\n",
    "        p1 = (Pra_m @ tem_can - p_ra1)**2\n",
    "        p1e = time.perf_counter()\n",
    "        # part1 += p1e-p1s\n",
    "        # p2s = time.perf_counter()\n",
    "        # p2 = np.repeat(p1[:, np.newaxis], p_ra1.shape[0], axis=1)\n",
    "        # p2e = time.perf_counter()\n",
    "        # part2 += p2e-p2s\n",
    "        # p3s = time.perf_counter()\n",
    "        # p3 = (p2 - p_ra1[:, np.newaxis])**2 \n",
    "        # p3e = time.perf_counter()\n",
    "        # part3 += p3e-p3s\n",
    "        # ss = (np.repeat((Pra_m @ tem_can)[:, np.newaxis], p_ra1.shape[0], axis=1) - p_ra1[:, np.newaxis])**2\n",
    "b = time.perf_counter()\n",
    "print(f\"Tot: {b-a}; p1: {part1/(b-a)}; p2: {part2/(b-a)}; p3: {part3/(b-a)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Pra_m @ tem_can - p_ra1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = np.zeros((d, d))\n",
    "Te = np.random.standard_exponential(d) # Initial Y_i^0\n",
    "Id = np.eye(d)\n",
    "U = u_hat # eigenvectors of \\hat(rho) found using inversion, initial V_i^0\n",
    "Lamb = Te/Te.sum() # gamma^0\n",
    "U = u_hat # eigenvectors of \\hat(rho) found using inversion, initial V_i^0\n",
    "be = 1\n",
    "Pra_m = npa(Pra).reshape((I, J))\n",
    "for i in range(600):\n",
    "    for j in range(d):\n",
    "        Te_can = Te.copy() \n",
    "        Te_can[j] = Te[j] * np.exp(be * np.random.uniform(-0.5, 0.5, 1)) # \\tilde(Y)_i = exp(y ~ U(-0.5, 0.5)) Y_i^t-1\n",
    "        L_can = Te_can/Te_can.sum() # \\tilde(gamma)_i = \\tilde(Y_i)/sum_j^d(\\tilde(Y_j))\n",
    "        tem_can = (U @ np.diag(L_can) @ np.conj(U.T)).flatten(order=\"F\") # gamma * U * U^T (U = V in paper)\n",
    "        tem = (U @ np.diag(Lamb) @ np.conj(U.T)).flatten(order=\"F\")\n",
    "        ss1 = (Pra_m @ tem_can - p_ra1)**2\n",
    "        ss2 = (Pra_m @ tem - p_ra1)**2\n",
    "        # ss1 = (np.repeat((Pra_m @ tem_can)[:, np.newaxis], p_ra1.shape[0], axis=1) - p_ra1[:, np.newaxis])**2\n",
    "        # ss2 = (np.repeat((Pra_m @ tem)[:, np.newaxis], p_ra1.shape[0], axis=1)- p_ra1[:, np.newaxis])**2\n",
    "        ss = (ss1 - ss2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g():\n",
    "    import jax\n",
    "    import jax.random as rd\n",
    "    import jax.numpy as jnp\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    rho = jnp.zeros((d, d))\n",
    "    key, subkey = rd.split(key)\n",
    "    Te = rd.exponential(subkey, (d,))# np.random.standard_exponential(d) # Initial Y_i^0\n",
    "    Id = jnp.eye(d)#np.eye(d)\n",
    "    U = jnp.asarray(u_hat) # eigenvectors of \\hat(rho) found using inversion, initial V_i^0\n",
    "    Lamb = Te/Te.sum() # gamma^0\n",
    "    be = 1\n",
    "    p_ra1 = jnp.asarray(p_ra1)\n",
    "    Pra_m = jnp.asarray(Pra).reshape((I, J))\n",
    "    for i in range(10):\n",
    "        for j in range(d):\n",
    "            Te_can = Te.copy()\n",
    "            key, subkey = rd.split(key)\n",
    "            Te_can.at[j].set(Te[j] * jnp.exp(be * rd.uniform(subkey, (1,), minval=-0.5, maxval=0.5))[0]) # \\tilde(Y)_i = exp(y ~ U(-0.5, 0.5)) Y_i^t-1\n",
    "            L_can = Te_can/Te_can.sum() # \\tilde(gamma)_i = \\tilde(Y_i)/sum_j^d(\\tilde(Y_j))\n",
    "            tem_can = (U @ jnp.diag(L_can) @ jnp.conj(U.T)).flatten(order=\"F\") # gamma * U * U^T (U = V in paper)\n",
    "            tem = (U @ jnp.diag(Lamb) @ jnp.conj(U.T)).flatten(order=\"F\")\n",
    "            ss1 = (jnp.repeat((Pra_m @ tem_can)[:, jnp.newaxis], p_ra1.shape[0], axis=1) - p_ra1[:, jnp.newaxis])**2\n",
    "            ss2 = (jnp.repeat((Pra_m @ tem)[:, jnp.newaxis], p_ra1.shape[0], axis=1)- p_ra1[:, jnp.newaxis])**2\n",
    "            ss = (ss1 - ss2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'p_ra1' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/Documents/thesis/python_port.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/daniel/Documents/thesis/python_port.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mlprun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m-f g g()\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/road_segmentation/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2305\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2304\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2305\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2306\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/envs/road_segmentation/lib/python3.10/site-packages/line_profiler/ipython_extension.py:104\u001b[0m, in \u001b[0;36mLineProfilerMagics.lprun\u001b[0;34m(self, parameter_s)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m         profile\u001b[39m.\u001b[39;49mrunctx(arg_str, global_ns, local_ns)\n\u001b[1;32m    105\u001b[0m         message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mSystemExit\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/road_segmentation/lib/python3.10/site-packages/line_profiler/line_profiler.py:162\u001b[0m, in \u001b[0;36mLineProfiler.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_by_count()\n\u001b[1;32m    161\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     exec(cmd, \u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m)\n\u001b[1;32m    163\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisable_by_count()\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/home/daniel/Documents/thesis/python_port.ipynb Cell 10\u001b[0m in \u001b[0;36mg\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/thesis/python_port.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m Lamb \u001b[39m=\u001b[39m Te\u001b[39m/\u001b[39mTe\u001b[39m.\u001b[39msum() \u001b[39m# gamma^0\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/thesis/python_port.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m be \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/daniel/Documents/thesis/python_port.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m p_ra2 \u001b[39m=\u001b[39m p_ra1\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/thesis/python_port.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m p_ra1 \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(p_ra2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/daniel/Documents/thesis/python_port.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m Pra_m \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39masarray(Pra)\u001b[39m.\u001b[39mreshape((I, J))\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'p_ra1' referenced before assignment"
     ]
    }
   ],
   "source": [
    "%lprun -f g g()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main MH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m Pra_m \u001b[38;5;241m=\u001b[39m npa(Pra)\u001b[38;5;241m.\u001b[39mreshape((I, J))\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Iter \u001b[38;5;241m+\u001b[39m burnin):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d): \u001b[38;5;66;03m# Loop for Y_i       \u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def f():\n",
    "# Main part\n",
    "rho = np.zeros((d, d))\n",
    "Te = np.random.standard_exponential(d) # Initial Y_i^0\n",
    "Id = np.eye(d)\n",
    "U = u_hat # eigenvectors of \\hat(rho) found using inversion, initial V_i^0\n",
    "Lamb = Te/Te.sum() # gamma^0\n",
    "ro = 1/2\n",
    "S = (rho_hat + np.conj(rho_hat.T))/2\n",
    "be = 1\n",
    "\n",
    "gamm = n_size/2 # lambda in paper \n",
    "entry = []\n",
    "Iter = 500\n",
    "burnin = 100\n",
    "start_time = time.time()\n",
    "Pra_m = npa(Pra).reshape((I, J))\n",
    "assert False\n",
    "for t in range(Iter + burnin):\n",
    "    for j in range(d): # Loop for Y_i       \n",
    "        Te_can = Te.copy() \n",
    "        Te_can[j] = Te[j] * np.exp(be * np.random.uniform(-0.5, 0.5, 1)) # \\tilde(Y)_i = exp(y ~ U(-0.5, 0.5)) Y_i^t-1\n",
    "        L_can = Te_can/Te_can.sum() # \\tilde(gamma)_i = \\tilde(Y_i)/sum_j^d(\\tilde(Y_j))\n",
    "        tem_can = (U @ np.diag(L_can) @ np.conj(U.T)).flatten(order=\"F\") # gamma * U * U^T (U = V in paper)\n",
    "        tem = (U @ np.diag(Lamb) @ np.conj(U.T)).flatten(order=\"F\") # prev gamma * U * U^T\n",
    "        #ss = (npa([tem_can.T @ x - p_ra1 for x in Pra])**2 - npa([tem.T @ x - p_ra1 for x in Pra])**2).sum() # l^prob: sum_a sum_s (Tr(v P^a_s) - hat(p^_a,s))^2\n",
    "        # ss1 = (np.repeat((Pra_m @ tem_can)[:, np.newaxis], p_ra1.shape[0], axis=1) - p_ra1[:, np.newaxis])**2\n",
    "        # ss2 = (np.repeat((Pra_m @ tem)[:, np.newaxis], p_ra1.shape[0], axis=1)- p_ra1[:, np.newaxis])**2\n",
    "        ss1 = (Pra_m @ tem_can - p_ra1)**2\n",
    "        ss2 = (Pra_m @ tem - p_ra1)**2\n",
    "        ss = (ss1 - ss2).sum()\n",
    "        r_prior = (ro-1) * np.log(Te_can[j]/Te[j]) - Te_can[j] + Te[j] # other part of R acceptance ratio\n",
    "        ap = -gamm*np.real(ss) # other part (why use np.real?)\n",
    "        if np.log(np.random.uniform(0, 1, 1)) <= ap + r_prior: Te = Te_can # if value above draw from U(0,1), then update\n",
    "        Lamb = Te/Te.sum() # gamma\n",
    "    for j in range(d): # Loop for V_i\n",
    "        U_can = U.copy()\n",
    "        U_can[:, j] = norm_complex(U[:,j] + np.random.multivariate_normal(np.zeros(d*2),np.eye(d*2)/100, size=(1)).view(np.complex128)) # Sample U/V from the unit sphere (not sure why we add to previous value)\n",
    "        tem_can = (U_can @ np.diag(Lamb) @ np.conj(U_can.T)).flatten(order=\"F\") # gamma * U * U^T\n",
    "        tem = (U @ np.diag(Lamb) @ np.conj(U.T)).flatten(order=\"F\") # gamma * U_t-1 * U^T_t-1\n",
    "        # ss = (npa([tem_can.T @  x - p_ra1 for x in Pra])**2 - npa([tem.T @ x - p_ra1 for x in Pra])**2).sum() # l^prob: sum_a sum_s (Tr(v P^a_s) - hat(p^_a,s))^2\n",
    "        # ss1 = (np.repeat((Pra_m @ tem_can)[:, np.newaxis], p_ra1.shape[0], axis=1) - p_ra1[:, np.newaxis])**2\n",
    "        # ss2 = (np.repeat((Pra_m @ tem)[:, np.newaxis], p_ra1.shape[0], axis=1)- p_ra1[:, np.newaxis])**2\n",
    "        ss1 = (Pra_m @ tem_can - p_ra1)**2\n",
    "        ss2 = (Pra_m @ tem - p_ra1)**2\n",
    "        ss = (ss1 - ss2).sum()\n",
    "        ap = -gamm * np.real(ss) # other part of A accep ratio\n",
    "        if np.log(np.random.uniform(0, 1, 1)) <= ap: U = U_can # if value above draw from U(0,1), then update\n",
    "\n",
    "    if t > burnin:\n",
    "        rho = U @ np.diag(Lamb) @ np.conj(U.T)/(t - burnin) + rho*(1-1/(t-burnin)) # approximate rho each time as rho_t = gamma_t * V_t * V_t^T /(t-burnin) + rho_t-1 / (1 - 1/(t-burnin)) -> the later we are, the more importance we give to prev rho\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.78868868e-05-1.40232699e-20j, 1.02899535e-04-2.30959736e-20j,\n",
       "       1.11638519e-05+2.86183372e-20j, ...,\n",
       "       1.20184126e-05-0.00000000e+00j, 4.40831818e-05+1.15177255e-20j,\n",
       "       1.13402746e-05+0.00000000e+00j])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "mid\n",
      "1\n",
      "mid\n",
      "2\n",
      "mid\n",
      "3\n",
      "mid\n",
      "4\n",
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 5.37994 s\n",
      "File: /tmp/ipykernel_27398/1258079928.py\n",
      "Function: f at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def f():\n",
      "     2                                               # Main part\n",
      "     3         1      16203.0  16203.0      0.0      rho = np.zeros((d, d))\n",
      "     4         1      20603.0  20603.0      0.0      Te = np.random.standard_exponential(d) # Initial Y_i^0\n",
      "     5         1      31010.0  31010.0      0.0      Id = np.eye(d)\n",
      "     6         1       1886.0   1886.0      0.0      U = u_hat # eigenvectors of \\hat(rho) found using inversion\n",
      "     7         1      49238.0  49238.0      0.0      Lamb = Te/Te.sum() # gamma^0\n",
      "     8         1       1397.0   1397.0      0.0      ro = 1/2\n",
      "     9         1      31010.0  31010.0      0.0      S = (rho_hat + np.conj(rho_hat.T))/2\n",
      "    10         1       1956.0   1956.0      0.0      be = 1\n",
      "    11                                           \n",
      "    12         1       2444.0   2444.0      0.0      gamm = n_size/2 # lambda in paper \n",
      "    13         1       1397.0   1397.0      0.0      entry = []\n",
      "    14         1       1397.0   1397.0      0.0      Iter = 500\n",
      "    15         1       1466.0   1466.0      0.0      burnin = 100\n",
      "    16         1       4330.0   4330.0      0.0      start_time = time.time()\n",
      "    17         1    2573328.0 2573328.0      0.0      Pra_m = npa(Pra).reshape((I, J))\n",
      "    18         5      15434.0   3086.8      0.0      for t in range(Iter + burnin):\n",
      "    19         5     471993.0  94398.6      0.0          print(t)\n",
      "    20        72     140385.0   1949.8      0.0          for j in range(d): # Loop for Y_i\n",
      "    21                                                       \n",
      "    22        72     400961.0   5568.9      0.0              Te_can = Te.copy() \n",
      "    23        72    1499506.0  20826.5      0.0              Te_can[j] = Te[j] * np.exp(be * np.random.uniform(-0.5, 0.5, 1)) # \\tilde(Y)_i = exp(y ~ U(-0.5, 0.5)) Y_i^t-1\n",
      "    24        72     497065.0   6903.7      0.0              L_can = Te_can/Te_can.sum() # \\tilde(gamma)_i = \\tilde(Y_i)/sum_j^d(\\tilde(Y_j))\n",
      "    25        72    5110688.0  70981.8      0.1              tem_can = (U @ np.diag(L_can) @ np.conj(U.T)).flatten(order=\"F\") # gamma * U * U^T (U = V in paper)\n",
      "    26        72    1268955.0  17624.4      0.0              tem = (U @ np.diag(Lamb) @ np.conj(U.T)).flatten(order=\"F\") # prev gamma * U * U^T\n",
      "    27                                                       #ss = (npa([tem_can.T @ x - p_ra1 for x in Pra])**2 - npa([tem.T @ x - p_ra1 for x in Pra])**2).sum() # l^prob: sum_a sum_s (Tr(v P^a_s) - hat(p^_a,s))^2\n",
      "    28        72 1117295399.0 15517991.7     20.8              ss1 = (np.repeat((Pra_m @ tem_can)[:, np.newaxis], p_ra1.shape[0], axis=1) - p_ra1[:, np.newaxis])**2\n",
      "    29        71 1136764064.0 16010761.5     21.1              ss2 = (np.repeat((Pra_m @ tem)[:, np.newaxis], p_ra1.shape[0], axis=1)- p_ra1[:, np.newaxis])**2\n",
      "    30        71  546553753.0 7697940.2     10.2              ss = (ss1 - ss2).sum()\n",
      "    31        71    2592398.0  36512.6      0.0              r_prior = (ro-1) * np.log(Te_can[j]/Te[j]) - Te_can[j] + Te[j] # other part of R acceptance ratio\n",
      "    32        71    1341945.0  18900.6      0.0              ap = -gamm*np.real(ss) # other part (why use np.real?)\n",
      "    33        71    2534071.0  35691.1      0.0              if np.log(np.random.uniform(0, 1, 1)) <= ap + r_prior: Te = Te_can # if value above draw from U(0,1), then update\n",
      "    34        71    1652742.0  23278.1      0.0              Lamb = Te/Te.sum() # gamma\n",
      "    35         4     325255.0  81313.8      0.0          print(\"mid\")\n",
      "    36        64     123198.0   1925.0      0.0          for j in range(d): # Loop for V_i\n",
      "    37        64     653309.0  10208.0      0.0              U_can = U.copy()\n",
      "    38        64   27211347.0 425177.3      0.5              U_can[:, j] = norm_complex(U[:,j] + np.random.multivariate_normal(np.zeros(d*2),np.eye(d*2)/100, size=(1)).view(np.complex128)) # Sample U/V from the unit sphere (not sure why we add to previous value)\n",
      "    39        64    2774821.0  43356.6      0.1              tem_can = (U_can @ np.diag(Lamb) @ np.conj(U_can.T)).flatten(order=\"F\") # gamma * U * U^T\n",
      "    40        64    1149181.0  17956.0      0.0              tem = (U @ np.diag(Lamb) @ np.conj(U.T)).flatten(order=\"F\") # gamma * U_t-1 * U^T_t-1\n",
      "    41                                                       # ss = (npa([tem_can.T @  x - p_ra1 for x in Pra])**2 - npa([tem.T @ x - p_ra1 for x in Pra])**2).sum() # l^prob: sum_a sum_s (Tr(v P^a_s) - hat(p^_a,s))^2\n",
      "    42        64  994441288.0 15538145.1     18.5              ss1 = (np.repeat((Pra_m @ tem_can)[:, np.newaxis], p_ra1.shape[0], axis=1) - p_ra1[:, np.newaxis])**2\n",
      "    43        64 1020965671.0 15952588.6     19.0              ss2 = (np.repeat((Pra_m @ tem)[:, np.newaxis], p_ra1.shape[0], axis=1)- p_ra1[:, np.newaxis])**2\n",
      "    44        64  505940901.0 7905326.6      9.4              ss = (ss1 - ss2).sum()\n",
      "    45        64    2087431.0  32616.1      0.0              ap = -gamm * np.real(ss) # other part of A accep ratio\n",
      "    46        64    3386566.0  52915.1      0.1              if np.log(np.random.uniform(0, 1, 1)) <= ap: U = U_can # if value above draw from U(0,1), then update\n",
      "    47                                           \n",
      "    48         4       8451.0   2112.8      0.0          if t > burnin:\n",
      "    49                                                       rho = U @ np.diag(Lamb) @ np.conj(U.T)/(t - burnin) + rho*(1-1/(t-burnin)) # approximate rho each time as rho_t = gamma_t * V_t * V_t^T /(t-burnin) + rho_t-1 / (1 - 1/(t-burnin)) -> the later we are, the more importance we give to prev rho\n",
      "    50                                               end_time = time.time()"
     ]
    }
   ],
   "source": [
    "%lprun -f f f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 17.715636730194092 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Took: {end_time - start_time} s\")\n",
    "mean_rho = np.mean((dens_ma - rho) @ np.conj((dens_ma - rho).T))\n",
    "mean_rho_hat = np.mean((dens_ma - rho_hat) @ np.conj((dens_ma - rho_hat).T))\n",
    "rho_evs = eig(rho)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "road_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
